[2022-10-17 13:04:20,615][__main__][INFO] - model:
  name: google/bert_uncased_L-2_H-128_A-2
  tokenizer: google/bert_uncased_L-2_H-128_A-2
processing:
  batch_size: 64
  max_length: 128
training:
  max_epochs: 5
  log_every_n_steps: 10
  deterministic: true
  limit_train_batches: null
  limit_val_batches: null

[2022-10-17 13:04:20,617][__main__][INFO] - Using the model: google/bert_uncased_L-2_H-128_A-2
[2022-10-17 13:04:20,618][__main__][INFO] - Using the tokenizer: google/bert_uncased_L-2_H-128_A-2
[2022-10-17 13:04:39,417][datasets.builder][WARNING] - Found cached dataset glue (C:/Users/asabh/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
