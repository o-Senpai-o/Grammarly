[2022-10-17 16:40:40,742][__main__][INFO] - model:
  name: google/bert_uncased_L-2_H-128_A-2
  tokenizer: google/bert_uncased_L-2_H-128_A-2
processing:
  batch_size: 64
  max_length: 128
training:
  max_epochs: 5
  log_every_n_steps: 10
  deterministic: true
  limit_train_batches: null
  limit_val_batches: null

[2022-10-17 16:40:40,744][__main__][INFO] - Using the model: google/bert_uncased_L-2_H-128_A-2
[2022-10-17 16:40:40,744][__main__][INFO] - Using the tokenizer: google/bert_uncased_L-2_H-128_A-2
